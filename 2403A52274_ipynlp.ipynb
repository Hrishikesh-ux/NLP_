{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1L6iJ45S/qmJU4qs/wmHz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hrishikesh-ux/NLP_/blob/main/2403A52274_ipynlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8z3WmlTU1o2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b4f9b7b",
        "outputId": "43e0c459-4f62-4d50-ab66-41d71cda7aee"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd6abaf5",
        "outputId": "b0e5650a-947a-4636-889f-1c6d57bd6806"
      },
      "source": [
        "pip install spacy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19d1f15f",
        "outputId": "af6ff45e-c73b-49ed-b87e-e9ca2bbff8de"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b0a9f85"
      },
      "source": [
        "The above cells install the NLTK and SpaCy libraries, and then download a small English language model for SpaCy (`en_core_web_sm`).\n",
        "You can now import and use these libraries in your notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy"
      ],
      "metadata": {
        "id": "fK8kr02fVd9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "health =\"T.B is being globally chronic disease nowadays many of the people are being affected by T.B. there are some symptoms like immediate weight LOSS , dry cough , Intense fever when see these kind Symptoms consult a Doctor \""
      ],
      "metadata": {
        "id": "8w18EWl9VlcY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(health)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRp8kJQaWJua",
        "outputId": "fabb545a-c470-4d22-9eee-7b076d5f7ebe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T.B',\n",
              " 'is',\n",
              " 'being',\n",
              " 'globally',\n",
              " 'chronic',\n",
              " 'disease',\n",
              " 'nowadays',\n",
              " 'many',\n",
              " 'of',\n",
              " 'the',\n",
              " 'people',\n",
              " 'are',\n",
              " 'being',\n",
              " 'affected',\n",
              " 'by',\n",
              " 'T.B',\n",
              " '.',\n",
              " 'there',\n",
              " 'are',\n",
              " 'some',\n",
              " 'symptoms',\n",
              " 'like',\n",
              " 'immediate',\n",
              " 'weight',\n",
              " 'LOSS',\n",
              " ',',\n",
              " 'dry',\n",
              " 'cough',\n",
              " ',',\n",
              " 'Intense',\n",
              " 'fever',\n",
              " 'when',\n",
              " 'see',\n",
              " 'these',\n",
              " 'kind',\n",
              " 'Symptoms',\n",
              " 'consult',\n",
              " 'a',\n",
              " 'Doctor']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(health)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFLGoVS4W9Yg",
        "outputId": "aed049ab-3b9d-47a8-b079-4fc3551f2e83"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T.B is being globally chronic disease nowadays many of the people are being affected by T.B.',\n",
              " 'there are some symptoms like immediate weight LOSS , dry cough , Intense fever when see these kind Symptoms consult a Doctor']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km61qjo3W7ch",
        "outputId": "417e4fa7-2be7-4812-8524-274c0de393e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quotes = word_tokenize(health)\n",
        "words_in_quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81rgaEo-XfZ6",
        "outputId": "a1c345da-9682-4e9c-fe1d-696d6907617f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T.B',\n",
              " 'is',\n",
              " 'being',\n",
              " 'globally',\n",
              " 'chronic',\n",
              " 'disease',\n",
              " 'nowadays',\n",
              " 'many',\n",
              " 'of',\n",
              " 'the',\n",
              " 'people',\n",
              " 'are',\n",
              " 'being',\n",
              " 'affected',\n",
              " 'by',\n",
              " 'T.B',\n",
              " '.',\n",
              " 'there',\n",
              " 'are',\n",
              " 'some',\n",
              " 'symptoms',\n",
              " 'like',\n",
              " 'immediate',\n",
              " 'weight',\n",
              " 'LOSS',\n",
              " ',',\n",
              " 'dry',\n",
              " 'cough',\n",
              " ',',\n",
              " 'Intense',\n",
              " 'fever',\n",
              " 'when',\n",
              " 'see',\n",
              " 'these',\n",
              " 'kind',\n",
              " 'Symptoms',\n",
              " 'consult',\n",
              " 'a',\n",
              " 'Doctor']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health = \"T.B is being globally chronic disease nowadays many of the people are being affected by T.B. there are some symptoms like immediate weight LOSS , dry cough , Intense fever when see these kind Symptoms consult a Docto\""
      ],
      "metadata": {
        "id": "lg4EvlS1XtC5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(health)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq8TzeydX_0f",
        "outputId": "36588f75-2391-4373-a884-5708cfd6892d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T.B',\n",
              " 'is',\n",
              " 'being',\n",
              " 'globally',\n",
              " 'chronic',\n",
              " 'disease',\n",
              " 'nowadays',\n",
              " 'many',\n",
              " 'of',\n",
              " 'the',\n",
              " 'people',\n",
              " 'are',\n",
              " 'being',\n",
              " 'affected',\n",
              " 'by',\n",
              " 'T.B',\n",
              " '.',\n",
              " 'there',\n",
              " 'are',\n",
              " 'some',\n",
              " 'symptoms',\n",
              " 'like',\n",
              " 'immediate',\n",
              " 'weight',\n",
              " 'LOSS',\n",
              " ',',\n",
              " 'dry',\n",
              " 'cough',\n",
              " ',',\n",
              " 'Intense',\n",
              " 'fever',\n",
              " 'when',\n",
              " 'see',\n",
              " 'these',\n",
              " 'kind',\n",
              " 'Symptoms',\n",
              " 'consult',\n",
              " 'a',\n",
              " 'Docto']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(health)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iy19YclYX_m",
        "outputId": "29daa36f-592f-435f-e7c9-67c59151face"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t.b',\n",
              " 'is',\n",
              " 'be',\n",
              " 'global',\n",
              " 'chronic',\n",
              " 'diseas',\n",
              " 'nowaday',\n",
              " 'mani',\n",
              " 'of',\n",
              " 'the',\n",
              " 'peopl',\n",
              " 'are',\n",
              " 'be',\n",
              " 'affect',\n",
              " 'by',\n",
              " 't.b',\n",
              " '.',\n",
              " 'there',\n",
              " 'are',\n",
              " 'some',\n",
              " 'symptom',\n",
              " 'like',\n",
              " 'immedi',\n",
              " 'weight',\n",
              " 'loss',\n",
              " ',',\n",
              " 'dri',\n",
              " 'cough',\n",
              " ',',\n",
              " 'intens',\n",
              " 'fever',\n",
              " 'when',\n",
              " 'see',\n",
              " 'these',\n",
              " 'kind',\n",
              " 'symptom',\n",
              " 'consult',\n",
              " 'a',\n",
              " 'docto']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "health = \"T.B is being globally chronic disease nowadays many of the people are being affected by T.B. there are some symptoms like immediate weight LOSS , dry cough , Intense fever when see these kind Symptoms consult a Doctor\"\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(health)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVOirIYUY6tV",
        "outputId": "68be6750-a5ee-4b43-abce-66a5e757f875"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T.B ---> t.b\n",
            "is ---> is\n",
            "being ---> be\n",
            "globally ---> global\n",
            "chronic ---> chronic\n",
            "disease ---> diseas\n",
            "nowadays ---> nowaday\n",
            "many ---> mani\n",
            "of ---> of\n",
            "the ---> the\n",
            "people ---> peopl\n",
            "are ---> are\n",
            "being ---> be\n",
            "affected ---> affect\n",
            "by ---> by\n",
            "T.B ---> t.b\n",
            ". ---> .\n",
            "there ---> there\n",
            "are ---> are\n",
            "some ---> some\n",
            "symptoms ---> symptom\n",
            "like ---> like\n",
            "immediate ---> immedi\n",
            "weight ---> weight\n",
            "LOSS ---> loss\n",
            ", ---> ,\n",
            "dry ---> dri\n",
            "cough ---> cough\n",
            ", ---> ,\n",
            "Intense ---> intens\n",
            "fever ---> fever\n",
            "when ---> when\n",
            "see ---> see\n",
            "these ---> these\n",
            "kind ---> kind\n",
            "Symptoms ---> symptom\n",
            "consult ---> consult\n",
            "a ---> a\n",
            "Doctor ---> doctor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(health)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv4CtruOaKmf",
        "outputId": "2349fda2-4f02-4b99-a67c-1058e01880c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T.B ---> t.b\n",
            "is ---> is\n",
            "being ---> being\n",
            "globally ---> glob\n",
            "chronic ---> chronic\n",
            "disease ---> diseas\n",
            "nowadays ---> nowaday\n",
            "many ---> many\n",
            "of ---> of\n",
            "the ---> the\n",
            "people ---> peopl\n",
            "are ---> ar\n",
            "being ---> being\n",
            "affected ---> affect\n",
            "by ---> by\n",
            "T.B ---> t.b\n",
            ". ---> .\n",
            "there ---> ther\n",
            "are ---> ar\n",
            "some ---> som\n",
            "symptoms ---> symptom\n",
            "like ---> lik\n",
            "immediate ---> immedy\n",
            "weight ---> weight\n",
            "LOSS ---> loss\n",
            ", ---> ,\n",
            "dry ---> dry\n",
            "cough ---> cough\n",
            ", ---> ,\n",
            "Intense ---> intens\n",
            "fever ---> fev\n",
            "when ---> when\n",
            "see ---> see\n",
            "these ---> thes\n",
            "kind ---> kind\n",
            "Symptoms ---> symptom\n",
            "consult ---> consult\n",
            "a ---> a\n",
            "Doctor ---> doct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = word_tokenize(health)\n",
        "for word in words:\n",
        "    print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDoJx8P-acUV",
        "outputId": "ffdfa781-49c1-49c3-845c-1d7145c90ab6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T.B ---> T.B\n",
            "is ---> is\n",
            "being ---> be\n",
            "globally ---> globally\n",
            "chronic ---> chronic\n",
            "disease ---> diseas\n",
            "nowadays ---> nowaday\n",
            "many ---> many\n",
            "of ---> of\n",
            "the ---> the\n",
            "people ---> peopl\n",
            "are ---> are\n",
            "being ---> be\n",
            "affected ---> affected\n",
            "by ---> by\n",
            "T.B ---> T.B\n",
            ". ---> .\n",
            "there ---> ther\n",
            "are ---> are\n",
            "some ---> som\n",
            "symptoms ---> symptom\n",
            "like ---> lik\n",
            "immediate ---> immediat\n",
            "weight ---> weight\n",
            "LOSS ---> LOSS\n",
            ", ---> ,\n",
            "dry ---> dry\n",
            "cough ---> cough\n",
            ", ---> ,\n",
            "Intense ---> Intens\n",
            "fever ---> fever\n",
            "when ---> when\n",
            "see ---> see\n",
            "these ---> thes\n",
            "kind ---> kind\n",
            "Symptoms ---> Symptom\n",
            "consult ---> consult\n",
            "a ---> a\n",
            "Doctor ---> Doctor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health = \"T.B is being globally chronic disease nowadays many of the people are being affected by T.B. there are some symptoms like immediate weight LOSS , dry cough , Intense fever when see these kind Symptoms consult a Doctor\"\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(health)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtKQTg0naqof",
        "outputId": "3031927a-8f2b-4936-f135-e78edebe0b76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T.B ---> T.B\n",
            "is ---> is\n",
            "being ---> being\n",
            "globally ---> globally\n",
            "chronic ---> chronic\n",
            "disease ---> disease\n",
            "nowadays ---> nowadays\n",
            "many ---> many\n",
            "of ---> of\n",
            "the ---> the\n",
            "people ---> people\n",
            "are ---> are\n",
            "being ---> being\n",
            "affected ---> affected\n",
            "by ---> by\n",
            "T.B ---> T.B\n",
            ". ---> .\n",
            "there ---> there\n",
            "are ---> are\n",
            "some ---> some\n",
            "symptoms ---> symptom\n",
            "like ---> like\n",
            "immediate ---> immediate\n",
            "weight ---> weight\n",
            "LOSS ---> LOSS\n",
            ", ---> ,\n",
            "dry ---> dry\n",
            "cough ---> cough\n",
            ", ---> ,\n",
            "Intense ---> Intense\n",
            "fever ---> fever\n",
            "when ---> when\n",
            "see ---> see\n",
            "these ---> these\n",
            "kind ---> kind\n",
            "Symptoms ---> Symptoms\n",
            "consult ---> consult\n",
            "a ---> a\n",
            "Doctor ---> Doctor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Lc4J5KXjbWua",
        "outputId": "907903a6-da28-4143-b77c-fe8c6e40051f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\",pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tYV4XSupbmgF",
        "outputId": "15328ab3-8793-4c23-a194-3acc08fd1026"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer,SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "Lanc = LancasterStemmer()\n",
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'Regexp Stemmer','WordNetLemmatizer'))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word,porter.stem(word),snowball.stem(word),Lanc.stem(word),regexp.stem(word),lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGSjMpeRbsbs",
        "outputId": "8585dc53-349b-42e6-f30f-7f3bb6225dcb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNetLemmatizer                                 \n",
            "friend              friend              friend              friend                        friend                                  friend                                            \n",
            "friendship          friendship          friendship          friend                        friendship                              friendship                                        \n",
            "friends             friend              friend              friend                        friend                                  friend                                            \n",
            "friendships         friendship          friendship          friend                        friendship                              friendship                                        \n"
          ]
        }
      ]
    }
  ]
}